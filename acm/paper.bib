@string{i3etc = "{IEEE} {T}ransactions on {C}omputers"}

@inproceedings{Im01,
  author =	 {Im, E.-J. and Yelick, K.},
  title =	 {Optimizing Sparse Matrix Computations for Register
                  Reuse in SPARSITY},
  booktitle =	 {Proc. of ICCS},
  year =	 {2001},
  pages =	 {127--136},
} 

@inproceedings{Williams07,
  author =	 {Williams, S. and Oliker, L. and Vuduc, R. and Shalf,
                  J. and Yelick, K. and Demmel, J.},
  title =	 {Optimization of sparse matrix-vector multiplication
                  on emerging multicore platforms},
  booktitle =	 {Proc. SC '07},
  series =	 {},
  year =	 {2007},
  pages =	 {38:1--38:12},
} 

@TechReport{Akbudak12,
  author =	 "K. Akbudak and E. Kayaaslan and C. Aykanat",
  title =	 "Hypergraph-Partitioning-Based Models and Methods for
                  Exploiting Cache Locality in Sparse-Matrix Vector
                  Multiplication",
  institution =	 "Bilkent University",
  year =	 "2012",
  misc =	 "http://arxiv.org/abs/1202.3856",
  Tnumber =	 "arXiv:1202.3856"
}

@article{Yzelman11,
  author =	 {A. N. Yzelman and Rob H. Bisseling},
  title =	 {Two-dimensional cache-oblivious sparse matrix-vector
                  multiplication},
  journal =	 {Parallel Computing},
  volume =	 {37},
  number =	 {12},
  year =	 {2011},
  pages =	 {806-819},
}

@article{Nishtala07,
  author =	 {Nishtala, R. and Vuduc, R. and Demmel, J. and
                  Yelick, K.},
  title =	 {When cache blocking of sparse matrix vector multiply
                  works and why},
  journal =	 {Appl. Algebra Eng., Commun. Comput.},
  issue\_date =	 {May 2007},
  volume =	 {18},
  number =	 {3},
  month =	 may,
  year =	 {2007},
  pages =	 {297--311}
} 

@inproceedings{Vuduc05,
  author =	 {R. Vuduc and J. Demmel and K. Yelic},
  title =	 {{OSKI}: A library of automatically tuned sparse
                  matrix kernels},
  booktitle =	 {Proc. SciDAC 2005, J. of Physics: Conference Series},
  year =	 {2005}
} 

@MastersThesis{Jain08,
  author =	 {Jain, A.},
  title =	 {{pOSKI}: An Extensible Autotuning Framework to
                  Perform Optimized SpMVs on Multicore Architecture},
  school =	 {UC Berkeley},
  year =	 {2008},
}

@article{Mellor-Crummey04,
  author =	 {Mellor-Crummey, J. and Garvin, J.},
  title =	 {Optimizing Sparse Matrix-Vector Product Computations
                  Using Unroll and Jam},
  journal =	 {Int. J. High Perform. Comput. Appl.},
  issue\_date =	 {May 2004},
  volume =	 {18},
  number =	 {2},
  month =	 may,
  year =	 {2004},
  OPTpages =	 {225--236},
} 

@inproceedings{Willcock06,
  author =	 {Willcock, J. and Lumsdaine, A.},
  title =	 {Accelerating sparse matrix computations via data
                  compression},
  booktitle =	 {Proc. of ICS},
  year =	 {2006},
  pages =	 {307--316},
} 

@inproceedings{Kourtis08,
  author =	 {Kourtis, K. and Goumas, G. and Koziris, N.},
  title =	 {Optimizing sparse matrix-vector multiplication using
                  index and value compression},
  booktitle =	 {Proc. 5th conference on Computing frontiers},
  series =	 {CF '08},
  year =	 {2008},
  pages =	 {87--96},
} 

@article{Krotkiewski10,
  author =	 {Krotkiewski, M. and Dabrowski, M.},
  title =	 {Parallel symmetric sparse matrix-vector product on
                  scalar multi-core {CPU}s},
  journal =	 {Parallel Comput.},
  issue\_date =	 {April, 2010},
  volume =	 {36},
  number =	 {4},
  month =	 apr,
  year =	 {2010},
  pages =	 {181--198},
} 


@techreport{Bell08,
  author =	 {N. Bell and M. Garland},
  title =	 {Efficient Sparse Matrix-Vector Multiplication on
                  {CUDA}},
  month =	 dec,
  year =	 2008,
  institution =	 {NVIDIA Corporation},
  type =	 {NVIDIA Technical Report},
  number =	 {NVR-2008-004},
}

@inproceedings{Bell09,
  author =	 {Bell, N. and Garland, M.},
  title =	 {Implementing sparse matrix-vector multiplication on
                  throughput-oriented processors},
  booktitle =	 {Proc. High Performance Computing Networking, Storage
                  and Analysis},
  series =	 {SC '09},
  year =	 {2009},
  location =	 {Portland, Oregon},
  pages =	 {18:1--18:11},
}


@techreport{ruiz:01,
  Author =	 {D. Ruiz},
  Institution =	 {Rutherford Appleton Lab., Oxon},
  Number =	 {RAL-TR-2001-034},
  Title =	 {A scaling algorithm to equilibrate both rows and
                  columns norms in matrices},
  Year =	 2001
}

@techreport{ruuc:11,
  Author =	 {D. Ruiz and B. U{\c{c}}ar},
  Institution =	 {INRIA},
  Number =	 {RR-7552},
  Title =	 {A symmetry preserving algorithm for matrix scaling},
  Year =	 {2011}
}

@InProceedings{Saule12-MTAAP,
  author =	 {E. Saule and {\"U}. {\c{C}}ataly{\"u}rek},
  title =	 {An Early Evaluation of the Scalability of Graph
                  Algorithms on the {Intel MIC} Architecture},
  booktitle =	 {IPDPS Workshop MTAAP},
  series =	 {},
  year =	 {2012},
}

@InProceedings{Eisenlohr12-TACC,
  author =	 {J. Eisenlor and D. Hudak and K. Tomko and T. Prince},
  title =	 {Dense Linear Algebra Factorization in {OpenMP} and
                  {Cilk Plus on Intel MIC}: Development Experiences
                  and Performance Analysis},
  booktitle =	 {TACC-Intel Highly Parallel Computing Symp.},
  year =	 {2012}
}

@InProceedings{Potluri12-TACC,
  author =	 {S. Potluri and K. Tomko and D. Bureddy
                  and D. K. Panda},
  title =	 {{Intra-MIC MPI} Communication using {MVAPICH2}:
                  Early Experience},
  booktitle =	 {TACC-Intel Highly Parallel Computing Symp.},
  year =	 {2012}
}

@InProceedings{Stock12-TACC,
  author =	 {K. Stock and L.-N. Pouchet and
                  P. Sadayappan},
  title =	 {Automatic Transformations for Effective Parallel
                  Execution on Intel Many Integrated Core},
  booktitle =	 {TACC-Intel Highly Parallel Computing Symp.},
  year =	 {2012}
}

@InProceedings{Zhou12-Cluster,
  author =	 {Z. Zhou and E. Saule and H. Aktulga and C. Yang and
                  E. Ng and P. Maris and J. Vary and
                  {\"U}. {\c{C}}ataly{\"u}rek},
  title =	 {An Out-of-core Eigensolver on {SSD}-equipped
                  Clusters},
  booktitle =	 {Proc. of IEEE Cluster},
  year =	 {2012},
  month =	 {Sep}
}


@inproceedings{Gori06,
  author =	 {Gori, M. and Pucci, A.},
  title =	 {Research Paper Recommender Systems: A Random-Walk
                  Based Approach},
  booktitle =	 {Proc. of IEEE/WIC/ACM Web Intelligence},
  year =	 {2006},
  OPTpages =	 {778--781},
} 

@article{Li09,
  author =	 {Li, J. and Willett, P.},
  title =	 {ArticleRank: a {PageRank}-based alternative to
                  numbers of citations for analyzing citation
                  networks},
  journal =	 {Proc of ASLIB },
  volume =	 {61},
  number =	 {6},
  year =	 {2009},
  OPTpages =	 {605--618}
}


@article{Ma08,
  author =	 {Ma, N. and Guan, J. and Zhao, Y.},
  title =	 {Bringing {PageRank} to the citation analysis},
  journal =	 {Inf. Process. Manage.},
  volume =	 {44},
  issue =	 {2},
  year =	 {2008},
  pages =	 {800--810},
} 

@article {Lao10,
  author =	 {Lao, N. and Cohen, W.},
  title =	 {Relational retrieval using a combination of
                  path-constrained random walks},
  journal =	 {Machine Learning},
  publisher =	 {Springer Netherlands},
  pages =	 {53--67},
  volume =	 {81},
  issue =	 {1},
  year =	 {2010}
}

@book{duer:86,
Author = {I. S. Duff and A. M. Erisman and J. K. Reid},
Publisher = {Oxford Univ. Press},
Title = {Direct Methods for Sparse Matrices},
Year = 1986}


@incollection{abdg:11b,
  Author =	 {P. Amestoy and A. Buttari and I. Duff and
                  A. Guermouche and J.-Y. L'Excellent and B. U\c{c}ar},
  Booktitle =	 {Ency. of Parallel Computing},
  Editor =	 {David A. Padua},
  Pages =	 {1232--1238},
  Title =	 {{MUMPS}},
  Year =	 {2011}
}


@article{Amestoy96,
  author =	 {Amestoy, P. and Davis, T. and Duff, I.},
  title =	 {An Approximate Minimum Degree Ordering Algorithm},
  journal =	 {SIAM J. Matrix Anal. Appl.},
  issue\_date =	 {Oct. 1996},
  volume =	 {17},
  number =	 {4},
  OPTmonth =	 oct,
  year =	 {1996},
  OPTissn =	 {0895-4798},
  pages =	 {886--905},
} 

@inproceedings{Pinar99,
  author =	 {Pinar, A. and Heath, M.},
  title =	 {Improving performance of sparse matrix-vector
                  multiplication},
  booktitle =	 {Proc. ACM/IEEE Supercomputing},
  OPTseries =	 {Supercomputing '99},
  year =	 {1999},
} 

@inproceedings{Cuthill69,
  author =	 {Cuthill, E. and McKee, J.},
  title =	 {Reducing the bandwidth of sparse symmetric matrices},
  booktitle =	 {Proc. ACM national conference},
  OPTseries =	 {ACM '69},
  year =	 {1969},
  pages =	 {157--172},
} 


@inproceedings{Buluc11,
  author =	 {Bulu\c{c}, A. and Williams, S. and Oliker, L. and
                  Demmel, J.},
  title =	 {Reduced-Bandwidth Multithreaded Algorithms for
                  Sparse Matrix-Vector Multiplication},
  booktitle =	 {Proc. IPDPS},
  OPTseries =	 {IPDPS '11},
  year =	 {2011},
  OPTisbn =	 {978-0-7695-4385-7},
  OPTpages =	 {721--733},
} 



@inproceedings{Belgin09,
  author =	 {Belgin, Mehmet and Back, Godmar and Ribbens, Calvin
                  J.},
  title =	 {Pattern-based sparse matrix representation for
                  memory-efficient SMVM kernels},
  booktitle =	 {Proc. of ICS},
  year =	 {2009},
  pages =	 {100--109},
} 


@inproceedings{Buluc2009SPAA,
  author =	 {Bulu\c{c}, A. and Fineman, J. and Frigo,
                  M. and Gilbert, J. and Leiserson, C.},
  title =	 {Parallel sparse matrix-vector and
                  matrix-transpose-vector multiplication using
                  compressed sparse blocks},
  booktitle =	 {Proc. SPAA '09},
  series =	 {},
  year =	 {2009},
  pages =	 {233--244},
  keywords =	 {compressed sparse blocks, compressed sparse columns,
                  compressed sparse rows, matrix transpose,
                  matrix-vector multiplication, multithreaded
                  algorithm, parallelism, span, sparse matrix, storage
                  format, work},
} 

@InProceedings{Kucuktunc12-ASONAM,
author =	 {Onur K{\"u}{\c{c}}{\"u}ktun{\c{c}} and Kamer Kaya and Erik Saule and
              {\"U}mit V. {\c{C}}ataly{\"u}rek},
title =	 {Fast Recommendation on Bibliographic Networks},
booktitle =	 {Proc. ASONAM'12},
series = {},
month =	 {Aug},
year =	 {2012},
}


@InProceedings{Kucuktunc12-DBRank,
author =	 {Onur K{\"u}{\c{c}}{\"u}ktun{\c{c}} and Erik Saule and Kamer Kaya and
              {\"U}mit V. {\c{C}}ataly{\"u}rek},
title =	 {Direction Awareness in Citation Recommendation},
booktitle =	 {Proc. of DBRank},
OPTpages =	 {6},
year =	 {2012}
}

@InProceedings{Catalyurek12-ICPP,
author = 	 {{\"U}mit V. {\c{C}}ataly{\"u}rek and Kamer Kaya and Bora U{\c{c}}ar},
title = 	 {On shared-memory parallelization of a sparse matrix scaling algorithm},
booktitle =    {Proc. of ICPP},
year = 	 {2012},
month = 	 {Sep},
}

@inproceedings{Aktulga12-Europar,
  author =	 {Hasan Metin Aktulga and Chao Yang and Esmond G. Ng
                  and Pieter Maris and James P. Vary},
  title =	 {Topology-Aware Mappings for Large-Scale Eigenvalue
                  Problems},
  booktitle =	 {Euro-Par},
  year =	 {2012},
  pages =	 {830-842},
  OPTcrossref =	 {DBLP:conf/europar/2012},
  OPTbibsource = {DBLP, http://dblp.uni-trier.de}
}



@Article{Zhang95,
author = 	 {Zhang, CT and Chou, KC},
title = 	 {An eigenvalue-eigenvector approach to predicting protein folding types},
journal = 	 {J. of Protein Chemistry},
year = 	 {1995},
volume = 	 {14},
number = 	 {5},
pages = 	 {309-26},
month = 	 jul,
}



@InProceedings{Sternberg2008,
author =	 {Sternberg, P. and Ng, E.G. and Yang, C. and Maris,
              P. and Vary, J.P. and Sosonkina, M. and Le, H.V.},
title =	 {Accelerating Configuration Interaction Calculations
              for Nuclear Structure},
booktitle =	 {Proc. of Supercomputing},
year =	 {2008},
}

@article{Maris201097,
title =	 "Scaling of ab-initio nuclear physics calculations on
              multicore computer architectures",
journal =	 "Procedia Computer Science",
volume =	 "1",
number =	 "1",
pages =	 "97 - 106",
year =	 "2010",
note =	 "ICCS 2010",
issn =	 "1877-0509",
doi =		 "10.1016/j.procs.2010.04.012",
author =	 "Pieter Maris and Masha Sosonkina and James P. Vary
              and Esmond Ng and Chao Yang",
}

@article{Aykanat88,
author =       {C. Aykanat and F. Ozguner and F. Ercal and P. Sadayappan},                                                          title =        {Iterative algorithms for solution of large sparse systems of linear equations on hypercubes},
journal =      i3etc,
year =         1988,
volume =       37,
number =       "",
pages =        {1554--1567},
month =        "Dec",
}     

@book{saad1996iterative,
title={Iterative methods for sparse linear systems},
author={Saad, Y.},
volume={620},
year={1996},
publisher={PWS publishing company Boston}
}                                                                                                                                                
@BOOK{bisseling04,
AUTHOR = "Rob H. Bisseling",
TITLE = "Parallel Scientific Computation:
     A Structured Approach using {BSP} and {MPI}",
YEAR = "2004",  
MONTH= mar,  
PUBLISHER = "Oxford University Press, Oxford, UK",
KEYWORDS = "BSP, conjugate gradient,
        dense, FFT, cyclic distribution, matmat,
        matvec, Monte Carlo, LU,  MPI, parallel,
        sparse, triangular, wavelets",
ISBN= "0-19-852939-2",
 }



@MISC{Saad94sparskit,
author = {Youcef Saad},
title = {SPARSKIT: a basic tool kit for sparse matrix computations - Version 2},
year = {1994}
}

@inproceedings{cramer2012openmp,
  title =	 {OpenMP Programming on Intel Xeon Phi Coprocessors:
                  An Early Performance Comparison},
  author =	 {Cramer, T. and Schmidl, D. and Klemm, M. and an Mey,
                  D.},
  booktitle =	 {Proc. of MARC},
  editors =	 {Lankes, S. and Clauss, C.},
  OPTisbn =	 {978-3-00-039545-1},
  OPTpages =	 {38-44},
  month =	 nov,
  year =	 {2012},
  annote =	 {a simple evaluation of conjugate gradient
                  application on Xeon Phi. Use naive bandwidth
                  estimation methods. No real info}
}

@INPROCEEDINGS{6270737,
  author =	 {Min Si and Ishikawa, Y.},
  booktitle =	 {Parallel and Distributed Processing Symposium
                  Workshops PhD Forum (IPDPSW), 2012 IEEE 26th
                  International},
  title =	 {Design of Direct Communication Facility for
                  Many-Core Based Accelerators},
  year =	 {2012},
  month =	 {may},
  volume =	 {},
  number =	 {},
  pages =	 {924 -929},
  keywords =	 {Acceleration;Computational modeling;Computer
                  architecture;Graphics processing
                  unit;Kernel;multiprocessing systems;peripheral
                  interfaces;DCFA;Intel Knights Ferry;Mellanox
                  Infiniband HCA;PCI Express bus;data transfer;direct
                  communication facility;direct communication facility
                  design;many-core based accelerators;many-core based
                  cluster;many-core memory
                  area;accelerator;cluster;direct
                  communication;infiniband;many-core;},
  doi =		 {10.1109/IPDPSW.2012.113},
  ISSN =	 {},
  annote =	 {try to allow fast direct communicatino between MIC
                  and the off-node world},
}

@INPROCEEDINGS{Vuduc02performanceoptimizations,
author = {Richard Vuduc and James W. Demmel and Katherine A. Yelick and Shoaib Kamil and Rajesh Nishtala and Benjamin Lee},
title = {Performance Optimizations and Bounds for Sparse Matrix-Vector Multiply},
booktitle = {In Proceedings of Supercomputing},
year = {2002}
}

@inproceedings{conf/sc/VuducDYKNL02,
added-at = {2013-01-31T00:00:00.000+0100},
author = {Vuduc, Rich and Demmel, James and Yelick, Katherine A. and Kamil, Shoaib and Nishtala, Rajesh and Lee, Benjamin C.},
biburl = {http://www.bibsonomy.org/bibtex/254e234f764e422b3d5c781dde9ef8f8b/dblp},
booktitle = {SC},
crossref = {conf/sc/2002},
editor = {Giles, Roscoe C. and Reed, Daniel A. and Kelley, Kathryn},
ee = {http://doi.acm.org/10.1145/762761.762822},
interhash = {6477d8833544f8d8db4f5b44fef63d56},
intrahash = {54e234f764e422b3d5c781dde9ef8f8b},
keywords = {dblp},
pages = {1-35},
publisher = {ACM},
timestamp = {2013-01-31T00:00:00.000+0100},
title = {Performance optimizations and bounds for sparse matrix-vector multiply.},
url = {http://dblp.uni-trier.de/db/conf/sc/sc2002.html#VuducDYKNL02},
year = {2002}
}

@techreport{Nishtala:CSD-04-1335,
Author = {Nishtala, Rajesh and Vuduc, Richard W. and Demmel, James W. and Yelick, Katherine A.},
Title = {Performance Modeling and Analysis of Cache Blocking in Sparse Matrix Vector Multiply},
Institution = {EECS Department, University of California, Berkeley},
Year = {2004},
URL = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2004/5535.html},
Number = {UCB/CSD-04-1335},
Abstract = {We consider the problem of building high-performance implementations of sparse matrix-vector multiply (SpM x V), or <i>y</i> = <i>y</i> + <i>A</i> * x, which is an important and ubiquitous computational kernel. Prior work indicates that cache blocking of SpM x V is extremely important for some matrix and machine combinations, with speedups as high as 3x. In this paper we present a new, more compact data structure for cache blocking for SpM x V and look at the general question of when and why performance improves. Cache blocking appears to be most effective when simultaneously 1) the vector <i>x</i> does not fit in cache 2) the vector <i>y</i> fits in cache 3) the non zeros are distributed throughout the matrix and 4) the non zero density is sufficiently high. In particular we find that cache blocking does not help with band matrices no matter how large <i>x</i> and <i>y</i> are since the matrix structure already lends itself to the optimal access pattern. <p>Prior work on performance modeling assumed that the matrices were small enough so that <i>x</i> and <i>y</i> fit in the cache. However when this is not the case, the optimal block sizes picked by these models may have poor performance motivating us to update these performance models. In contrast, the optimum block sizes predicted by the new performance models generally match the measured optimum block sizes and therefore the models can be used as a basis for a heuristic to pick the block size. <p>We conclude with architectural suggestions that would make processor and memory systems more amenable to SpM x V.}
}

@inproceedings{conf/iccS/ImY01,
added-at = {2011-06-28T00:00:00.000+0200},
author = {Im, Eun-Jin and Yelick, Katherine A.},
biburl = {http://www.bibsonomy.org/bibtex/283ad1eb8044194ca155a3d798a30942a/dblp},
booktitle = {International Conference on Computational Science (1)},
crossref = {conf/iccS/2001-1},
editor = {Alexandrov, Vassil N. and Dongarra, Jack and Juliano, Benjoe A. and Renner, Ren√© S. and Tan, Chih Jeng Kenneth},
ee = {http://dx.doi.org/10.1007/3-540-45545-0_22},
interhash = {81c1670081b4750f26d6fe5ab06ea5bd},
intrahash = {83ad1eb8044194ca155a3d798a30942a},
isbn = {3-540-42232-3},
keywords = {dblp},
pages = {127-136},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
timestamp = {2011-06-28T00:00:00.000+0200},
title = {Optimizing Sparse Matrix Computations for Register Reuse in SPARSITY.},
url = {http://dblp.uni-trier.de/db/conf/iccS/iccS2001-1.html#ImY01},
volume = 2073,
year = 2001
}

@inproceedings{Buluc:2009:PSM:1583991.1584053,
author = {Bulu\c{c}, Aydin and Fineman, Jeremy T. and Frigo, Matteo and Gilbert, John R. and Leiserson, Charles E.},
title = {Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks},
booktitle = {Proceedings of the twenty-first annual symposium on Parallelism in algorithms and architectures},
series = {SPAA '09},
year = {2009},
isbn = {978-1-60558-606-9},
location = {Calgary, AB, Canada},
pages = {233--244},
numpages = {12},
url = {http://doi.acm.org/10.1145/1583991.1584053},
doi = {10.1145/1583991.1584053},
acmid = {1584053},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {compressed sparse blocks, compressed sparse columns, compressed sparse rows, matrix transpose, matrix-vector multiplication, multithreaded algorithm, parallelism, span, sparse matrix, storage format, work},
} 

@inproceedings{Temam:1992:CBS:147877.148091,
author = {Temam, O. and Jalby, W.},
title = {Characterizing the behavior of sparse algorithms on caches},
booktitle = {Proc. of SuperComputing},
year = {1992},
isbn = {0-8186-2630-5},
pages = {578--587},
numpages = {10},
url = {http://dl.acm.org/citation.cfm?id=147877.148091},
acmid = {148091},
} 

@article{DBLP:journals/ijhpca/ShantharamCR11,
added-at = {2012-10-04T20:17:20.000+0200},
author = {Shantharam, Manu and Chatterjee, Anirban and Raghavan, Padma},
bibsource = {DBLP, http://dblp.uni-trier.de},
biburl = {http://www.bibsonomy.org/bibtex/2cff74979ab28e4232c3387732ea9485c/ytyoun},
doi = {10.1177/1094342011414748},
interhash = {dc838e3ed53f8831b1d0c21e5ee7548d},
intrahash = {cff74979ab28e4232c3387732ea9485c},
journal = {IJHPCA},
keywords = {SpMV sparse},
number = 3,
pages = {328-341},
timestamp = {2012-10-04T20:17:20.000+0200},
title = {Exploiting dense substructures for fast sparse matrix vector multiplication},
volume = 25,
year = 2011
}

@inproceedings{conf/ppsc/Toledo97,
added-at = {2003-04-25T00:00:00.000+0200},
author = {Toledo, S.},
booktitle = {PPSC},
date = {2003-04-25},
description = {dblp},
isbn = {0-89871-395-1},
keywords = {dblp},
publisher = {SIAM},
timestamp = {2003-04-25T00:00:00.000+0200},
title = {Improving Memory-System Performance of Sparse Matrix-Vector Multiplication.},
url = {http://dblp.uni-trier.de/db/conf/ppsc/ppsc1997.html#Toledo97},
year = 1997
}

@inproceedings{Liu:2013:ESM:2464996.2465013,
  author =	 {Liu, X. and Smelyanskiy, M. and Chow, E.
                  and Dubey, P.},
  title =	 {Efficient sparse matrix-vector multiplication on
                  x86-based many-core processors},
  booktitle =	 {Proc. of ICS},
  year =	 {2013},
  isbn =	 {978-1-4503-2130-3},
  OPTpages =	 {273--282},
  numpages =	 {10},
  url =		 {http://doi.acm.org/10.1145/2464996.2465013},
  doi =		 {10.1145/2464996.2465013},
  acmid =	 {2465013},
  keywords =	 {esb format, intel many integrated core architecture
                  (intel mic), intel xeon phi, knights corner, spmv},
} 

@inproceedings{Molka:2009:MPC:1636712.1637764,
author = {Molka, Daniel and Hackenberg, Daniel and Schone, Robert and Muller, Matthias S.},
title = {Memory Performance and Cache Coherency Effects on an Intel Nehalem Multiprocessor System},
booktitle = {Proceedings of the 2009 18th International Conference on Parallel Architectures and Compilation Techniques},
series = {PACT '09},
year = {2009},
isbn = {978-0-7695-3771-9},
pages = {261--270},
numpages = {10},
url = {http://dx.doi.org/10.1109/PACT.2009.22},
doi = {10.1109/PACT.2009.22},
acmid = {1637764},
address = {Washington, DC, USA},
keywords = {nehalem, multicore, cache coherency, bandwidth, latency},
} 


@inproceedings{conf/ipps/KreutzerHWFBB12,
  added-at =	 {2012-09-11T00:00:00.000+0200},
  author =	 {Kreutzer, M. and Hager, G. and Wellein,
                  G. and Fehske, H. and Basermann, A. and
                  Bishop, A.},
  biburl =
                  {http://www.bibsonomy.org/bibtex/2af5dc8a2041d497b28be5b8d1485084f/dblp},
  booktitle =	 {IPDPS Workshops},
  ee =
                  {http://doi.ieeecomputersociety.org/10.1109/IPDPSW.2012.211},
  interhash =	 {e9c433f83f101583167bfa809bd5c346},
  intrahash =	 {af5dc8a2041d497b28be5b8d1485084f},
  isbn =	 {978-1-4673-0974-5},
  keywords =	 {dblp},
  pages =	 {1696-1702},
  timestamp =	 {2012-09-11T00:00:00.000+0200},
  title =	 {Sparse Matrix-vector Multiplication on GPGPU
                  Clusters: A New Storage Format and a Scalable
                  Implementation.},
  url =
                  {http://dblp.uni-trier.de/db/conf/ipps/ipdps2012w.html#KreutzerHWFBB12},
  year =	 2012
}


@article{kumar2012accelerating,
title={Accelerating Sparse Matrix Kernels on Graphics Processing Units},
author={Kumar, M.K.},
year={2012}
}

@article{journals/concurrency/VazquezFG11,
added-at = {2011-05-06T00:00:00.000+0200},
author = {Vazquez, F. and Fern{\'a}ndez, Jos{\'e}-Jes{\'u}s and Garz{\'o}n, Ester M.},
biburl = {http://www.bibsonomy.org/bibtex/21aed41a235a5393b9aa2aa1f58f65793/dblp},
ee = {http://dx.doi.org/10.1002/cpe.1658},
interhash = {149b91636baa047541be4a24828724cd},
intrahash = {1aed41a235a5393b9aa2aa1f58f65793},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {dblp},
number = 8,
pages = {815-826},
timestamp = {2011-05-06T00:00:00.000+0200},
title = {A new approach for sparse matrix vector product on NVIDIA GPUs.},
url = {http://dblp.uni-trier.de/db/journals/concurrency/concurrency23.html#VazquezFG11},
volume = 23,
year = 2011
}

%%%% papers from Natasha

@article{SDY02,
author = {C. Shu and H. Ding and K. S. Yeo},
title = {Local radial basis function-based differential quadrature method and its application to solve two-dimensional incompressible {N}avier-{S}tokes equations},
pages = {941--954},
journal = {Comput. Meth. Appl. Mech. Engrg.},
year = {2003},
volume = {192},
},


@article{TAI1,
author = {A. I. Tolstykh},
title = {On using {RBF}-based differencing formulas for unstructured and mixed structured-unstructured grid calculations},
volume = {228},
pages = {4606--4624},
journal = {Proc. of the 16th IMACS World Congress},
  year = {2000}
},


@article{TAI2,
author = {A. I. Tolstykh and D. A. Shirobokov},
title = {On using radial basis functions in a ``finite difference mode'' with applications to elasticity problems},
volume = {33},
pages = {68--79},
journal = {Comput. Mech.},
  year = {2003}
},

@article{FLBWSC12,
author = {N. Flyer and E. Lehto and S. Blaise and G. B. Wright and A. St-Cyr},
title = {A guide to {RBF}-generated finite differences for nonlinear transport: {S}hallow water simulations on a sphere},
pages = {4078-4095},
journal = {J. Comput. Phys},
year = {2012},
  volume = {231},
},

@article{FoL11,
author = {B. Fornberg and E. Lehto},
title = {Stabilization of {RBF}-generated finite difference methods for convective {PDE}s},
journal = {J. Comput. Phys.},
year = {2011},
volume = {230},
  pages = {2270--2285},
},

@article{WrFo06,
author = {G. B. Wright and B. Fornberg},
title = {Scattered node compact finite difference-type formulas generated from radial basis functions},
pages = {99--123},
journal = {J. Comput. Phys.},
year = {2006},
  volume = {212},
},

@TechReport{Saule13-ARXIV,
  author =	 {E. Saule and K. Kaya and {\"{U}}. 
                  {\c{C}}ataly{\"{u}}rek},
  title =	 {Performance Evaluation of Sparse Matrix
                  Multiplication Kernels on Intel Xeon Phi},
  OPTinstitution =	 {ArXiv},
  year =	 {2013},
  number =	 {arXiv1302.1078},
  OPTmonth =	 feb,
  url =		 {http://arxiv.org/abs/1302.1078},
  pdf =		 baseurl:esaule:publis # {arxiv13-SKC.pdf}
}

@Article{Koren05,
  author =	 {Y. Koren},
  title =	 {Drawing Graphs by Eigenvectors: Theory and Practice},
  journal =	 {Computers and Mathematics with Applications},
  year =	 {2005},
  volume =	 {49},
  pages =	 {1867--1888},
  OPTmonth =	 {},
  OPTnote =	 {},
  keywords =	 {graph drawing, graph layout, spectral layout,
                  eigenvectors},
  where =	 {graph_drawing/Koren05.pdf},
  annote =	 {This paper present spectral methods to draw
                  graphs. It basically rely on eigen vector extraction
                  to draw graphs. They show a model which minimizes
                  the pair wise distance of the vertices which shares
                  an edge while trying to maximize the drawing
                  area. The drawing is normalized by enforcing
                  constraint on the variance of each dimension and
                  their covariance. This has a lot of good property
                  like dimensional scale invariance and orthogonalite
                  of the vectors position in each dimension. In other
                  words, a project of a 3d plot is the optimal 2d
                  plot.\\They show that this model is equivalent to
                  the extraction of the eigen vector of the laplacian
                  of the adjacency matrix of the graph.\\They also
                  show the same formulation is equivalent to placing
                  each vertex at the centroid of its neighboors.\\This
                  paper is heavy on linear algebra but quite
                  enlightful. }
}

@inproceedings{Brin98,
  author =	 {Brin, S. and Page, L.},
  title =	 {The anatomy of a large-scale hypertextual Web search
                  engine},
  OPTbooktitle = {Proc. of World Wide Web},
  booktitle =	 {Proc. of WWW},
  year =	 {1998},
  keywords =	 {graph, page rank, eigensolving, recommender},
  OPTpages =	 {107--117},
} 


@article{LOBPCG,
  Author =	 {A.~V.~Knyazev},
  Journal =	 {SIAM Journal on Scientific Computing},
  Number =	 {2},
  Pages =	 {517--541},
  Title =	 {Toward the Optimal Preconditioned Eigensolver:
                  Locally Optimal Block Preconditioned Conjugate
                  Gradient Method},
  Volume =	 {23},
  Year =	 {2001}
}

@Article{Kucuktunc13-SNAM,
  author =	 {O. K{\"{u}}{\c{c}}{\"{u}}ktun{\c{c}} and K. Kaya and E. Saule and
                  {\"{U}}. {\c{C}}ataly{\"{u}}rek},
  title =	 {Fast Recommendation on Bibliographic Networks with
                  Sparse-Matrix Ordering and Partitioning},
  journal =	 {Social Network Analysis and Mining},
  year =	 {2013},
  url =		 baseurl:esaule:publis#{snam13-KKSC.pdf}
}

@article{journals/tog/BolzFGS03,
added-at = {2006-02-09T00:00:00.000+0100},
author = {Bolz, J. and Farmer, I. and Grinspun, E. and Schr{\"o}der, P.},
biburl = {http://www.bibsonomy.org/bibtex/2e1800f9f56890d269e2ebe100a58bec8/dblp},
date = {2006-02-09},
description = {dblp},
ee = {http://doi.acm.org/10.1145/882262.882364},
interhash = {210e5da8b15248bcdf32eca43598ba98},
intrahash = {e1800f9f56890d269e2ebe100a58bec8},
journal = {ACM Trans. Graph.},
keywords = {dblp},
number = 3,
pages = {917-924},
timestamp = {2006-02-09T00:00:00.000+0100},
title = {Sparse matrix solvers on the GPU: conjugate gradients and multigrid.},
url = {http://dblp.uni-trier.de/db/journals/tog/tog22.html#BolzFGS03},
volume = 22,
year = 2003
}



@article{CDNT,
   author = {P. P. Chinchapatnam and K. Djidjeli and P. B. Nair and M. Tan},
   title = {A compact {RBF-FD} based meshless method for the incompressible {N}avier-{S}tokes equations},
   volume = {223},
   pages = {275--290},
   journal = {J. Eng. Maritime Env.},
   year = {2009}
}

@article{SPLM,
   author = {D. Stevens and H. Power and M. Lees and H. Morvan},
   title = {The use of {PDE} centers in the local {RBF} Hermitean method for {3D} convective-diffusion problems},
   volume = {228},
   pages = {4606--4624},
   journal = {J. Comput. Phys.},
   year = {2009}
}

@article{Bayona13,
   author = {V. Bayona and M. Kindelan},
   title = {Propagation of premixed laminar flames in {3D} narrow open ducts using {R}BF-generated finite differences},
   journal = {Combustion Theory and Modelling},
   pages = {789--803},
   volume = {17},
   year = {2013}
}


% ----------------------------------------------------------------------
Memory Bandwidth ... (useful benchmarks)
2013 intel xeon phi ... (architural components)
A New approach ... for GPUs (special algorithmic features specific to NVIDIA)
Accelerating sparse matrix ... (M.S. thesis). (useful info on formats)
Sparse matrix kernels, auto-tuning (Vuduc), 455 p. thesis. 
Best Practice Guide for Phi (how to optimize). **** USEFUL. 
CUDA vs Phi for developers (discuss differences between CUDA and phi thread.)
Characterizing behavior of sparse algorithm on cache, 1992.  Paper on modeling cache use.  ***
Cache Traffic optimization ...2013 (CIlk, OpenMP) Relates to optimization.  Plots of different regimes: vectoriation, cache thrashing, cache-optimal.  
Efficient Sparse/Matrix-Vector Multiplication on CUDA (nice discussion of formats, different matrix patterns)
(use to justify our use of ELLPACK)
Efficient Sparse/Matrix-Vector Multiplication on X86-based on many-core processors. 
- discusses performance bounds, memory bandwidth measures, relation between compute time 
and memory transfer time.  Latency?  Discussion of cache-miss latency, of ELLPACK.  *** 
Proposes new format. 
Improving Memory-System Performance of Sparse Matrix Multiplication. (19p.)  *** (IMPORTANT)
Intel Xeon Phi Coprocessor Instrucdtion Set Instruction Manual, 2012. 725p. (learn to use masks and channels)
OpenMP Programing on Intel Xeon Phi Coprocessors ... , 2012. Microbenchmarks to measure time of 
different OMP directives. COULD BE USEFUL. Discusses spmv. Max theoretical performance is 20Gflops or 40 Gflops 
(not clear what the two numbers mean.) Plot of spmv w/ and w/o vectorization (why is there no difference when 
all threads are active?)
Optimization of Sparse Matrix-Vector Multiplication on Emerging Multicore Platforms. 2008. Williams. 
Important paper. 
Optimization Sparse Matrix Computations for Register Reuse in SPARSITY.  (Im and Yelick)
register blocking. 
Parallel sparse matrix-vector multiplication as a test case for hybrid MPI+OpenMP programming
Discusses bytes/flop. Performance graphs. Modeling.  USEFUL. 
Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel Xeon Phi. 2013 (Saule). 
Reduced-Bandwidth Multithreaded Algorithms for Sparse Matrix-Vector Multiplication, 2011, Buluc.  Register blocks. 
performance modelign. 
Sparse Matrix Reordering Algorithms for Cluster Identification
Sparse matrix-vector multiplication on GPGPU clusters: A new storage format and a scalable implementation, 2012.  (discusses ELLPACK_R) (only marginal to our paper)
When cache blocking of sparse matrix vector multiply works and why
--
LESS USEFUL
Building native applications for Intel ...
% ----------------------------------------------------------------------
% ADD References from Bollig thesis
